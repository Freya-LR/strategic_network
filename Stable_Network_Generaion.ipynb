{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Stable Network Generaion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Freya-LR/strategic_network/blob/master/Stable_Network_Generaion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuNIZkkUvjAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd1bc0b7-39cc-423f-c1ed-bc9a6430b6c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6hbbaNvvSR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "37f1d2ff-8cea-47aa-db8d-4969157a8bcb"
      },
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages, FigureCanvasPdf\n",
        "from matplotlib.figure import Figure\n",
        "import pandas as pd\n",
        "from itertools import chain, combinations\n",
        "import random as rnd\n",
        "import time\n",
        "import collections\n",
        "from multiprocessing import Pool\n",
        "from multiprocessing.dummy import Pool as ThreadPool\n",
        "import multiprocessing as mp\n",
        "import pickle\n",
        "!pip install xlsxwriter\n",
        "import openpyxl\n",
        "import xlsxwriter\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.rcParams['axes.labelsize'] = 16\n",
        "plt.rcParams['xtick.labelsize'] = 14\n",
        "plt.rcParams['ytick.labelsize'] = 14\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.6/dist-packages (1.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4QhaUiKvSR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# __ takes a graph, and a cost matrix, and returns the cost of each node as a vector\n",
        "def Cost_matrix(G,C):\n",
        "    adj_mat=nx.to_numpy_matrix(G)\n",
        "    mul_mat=np.matmul(C,np.transpose(adj_mat))\n",
        "    C_list=mul_mat.diagonal()\n",
        "    return C_list.tolist()[0]\n",
        "\n",
        "# Calculates node utility by taking the network (G), benefit vector and Cost matrix (this is used in the next function)\n",
        "def node_utility_general(node,G,b,C,depth=3):\n",
        "    z = nx.single_source_shortest_path_length(G,node,depth)\n",
        "    benefit = sum ( [ b[z[k]] for k in z]  )\n",
        "    cost = Cost_matrix(G,C)[node]\n",
        "    return benefit - cost\n",
        "\n",
        "# Returns all the node utilities\n",
        "def all_utils_general(g,b,C,depth=3):\n",
        "    node_utils= [node_utility_general(k,g,b,C,) for k in g.nodes()]\n",
        "    return node_utils\n",
        "\n",
        "#Calculates network utilities ofr each node and sets them as node attributes\n",
        "def set_network_util_attributes(g,b,C,depth=3):\n",
        "    utils=all_utils_general(g,b,C,depth=depth)\n",
        "    dict_util={}\n",
        "    for i in g.nodes():\n",
        "        dict_util[i]=round(utils[i],2)\n",
        "    nx.set_node_attributes(g, dict_util, 'utility')   \n",
        "    return g\n",
        "\n",
        "\"\"\" We seperate the sources of instability in networks into two categories: Frustration and envy. Frustration is when one node\n",
        "wants to remove one of its links. Envy is when two nodes want to form a link that currently doesn't exist. We look at the impact of each of these facots seperately\n",
        "by generating no frustration and no envy networks. Then we combine the two and find stable networks.\"\"\"\n",
        "\n",
        "#__for a given node, v, returns neighbors to whome v wants to disconnect the tie, and the difference in utility that is saved.\n",
        "def frust_test_general(g,v,b,cx,depth=3):\n",
        "    u_0=node_utility_general(v,g,b,cx,depth)\n",
        "    bad_neighbors=[]\n",
        "    for ng in g.neighbors(v):\n",
        "        g_tmp=g.copy()\n",
        "        g_tmp.remove_edge(v,ng)\n",
        "        u_new = node_utility_general(v,g_tmp,b,cx,depth)\n",
        "        if u_new > u_0:\n",
        "            bad_neighbors.append([v,ng,u_new-u_0])\n",
        "    return bad_neighbors\n",
        "\n",
        "#Takes network and cost and benefit parameters and returns the list of frustrated nodes\n",
        "def total_frust_list_general(g,b,c,depth=3):\n",
        "    total_list=[]\n",
        "    for v in g.nodes():\n",
        "        total_list+=frust_test_general(g,v,b,c,depth)\n",
        "    return total_list\n",
        "\n",
        "# Takes a network as an input, and returns all the links that both ends would agree with adding (envy list)\n",
        "def missed_opts_general(g,b,cx,depth=3):\n",
        "    node_utils= [node_utility_general(k,g,b,cx,depth) for k in g.nodes()]\n",
        "    missing_links=[]\n",
        "    for e in list(nx.edges(nx.complement(g))):\n",
        "        g_tmp=g.copy()\n",
        "        g_tmp.add_edge(*e)\n",
        "        us_shift=node_utility_general(e[0],g_tmp,b,cx,depth)-node_utils[e[0]]\n",
        "        ud_shift=node_utility_general(e[1],g_tmp,b,cx,depth)-node_utils[e[1]]\n",
        "        if ((us_shift>=0 and ud_shift>=0) and (abs(us_shift)+abs(ud_shift)!= 0)):\n",
        "            missing_links.append(e)\n",
        "    return missing_links\n",
        "\n",
        "#Takes a network, starts removing edges till it gets to a no-frustraction network\n",
        "def find_no_frustration_network_general(g,b,cx,depth=3,M=1000):\n",
        "    f_list=total_frust_list_general(g,b,cx,depth)\n",
        "    g_tmp=g.copy()\n",
        "    while ((f_list) and (M>0)):\n",
        "        e_rem=rnd.choice(f_list)\n",
        "        g_tmp.remove_edge(e_rem[0],e_rem[1])\n",
        "        f_list=total_frust_list_general(g_tmp,b,cx,depth)\n",
        "        M=M-1\n",
        "    return g_tmp,M\n",
        "#Takes a network, starts adding links till it gets to a no-envy network\n",
        "\n",
        "def find_no_envy_network_general(g,b,cx,depth=3,M=1000):\n",
        "    en_list=missed_opts_general(g,b,cx,depth)\n",
        "    g_tmp=g.copy()\n",
        "    while ((en_list) and (M>0)):\n",
        "        e_add=rnd.choice(en_list)\n",
        "        g_tmp.add_edge(*e_add)\n",
        "        en_list=missed_opts_general(g_tmp,b,cx,depth)\n",
        "        #print(len(en_list))\n",
        "        M=M-1\n",
        "    return g_tmp,M\n",
        "\n",
        "\"\"\"Here we combine the two factors to find stable networks. The following function takes network parameters, first calculates and sets\n",
        "utilities of each node. Then create a list of frustrated nodes and envy-generating links. Then at each time step moves one step\n",
        "towards lowering envy and one step towards reducing frustration (M determines the number of steps in each process). depth is the \n",
        "maximum distance for which node payoffs are calculated.\"\"\"\n",
        "\n",
        "def find_stable_network_general(g,b,cx,depth=3,N=1000,M=1):\n",
        "    Steps=N\n",
        "    set_network_util_attributes(g,b,cx,depth=depth)\n",
        "    g_sequence=[]\n",
        "    gt=g.copy()\n",
        "    L1=total_frust_list_general(gt,b,cx,depth)\n",
        "    L2=missed_opts_general(gt,b,cx,depth)\n",
        "    while ((len(L1)>0 or (len(L2)>0)) and (N>0)):\n",
        "        g_no_frust,Mf=find_no_frustration_network_general(gt,b,cx,depth,M)\n",
        "        g_no_envy,Me=find_no_envy_network_general(g_no_frust,b,cx,depth,M)\n",
        "        gt=g_no_envy\n",
        "        L1=total_frust_list_general(gt,b,cx)\n",
        "        L2=missed_opts_general(gt,b,cx)\n",
        "        N=N-1\n",
        "        set_network_util_attributes(gt,b,cx,depth=depth)\n",
        "        g_sequence.append(gt)\n",
        "        #print(N)\n",
        "    return gt,Steps-N,g_sequence\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"The following 3 functions are related to the special case of seperable cost\"\"\"\n",
        "\n",
        "#This function creates a cost matrix for the special case where costs are sepearble, which is when Cij = Ci + Cj, thus we need to \n",
        "#start with a cost vector (Cvec)\n",
        "def seperable_cost(Cvec):\n",
        "    n=len(Cvec)   \n",
        "    CM=np.zeros((n,n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            CM[i,j]=Cvec[i]\n",
        "    return CM\n",
        "\n",
        "#returns the total utility (the assumption node utilities are already registered in the network)\n",
        "\n",
        "def total_utility(G):\n",
        "    U=0\n",
        "    for i in G.nodes():\n",
        "        U+=G.nodes()[i]['utility']\n",
        "    return U\n",
        "\n",
        "# This reutnrs the unique effiecnet network (the algorithm is based on a paper (Heydari, Mosleh (2015))) \n",
        "        #if G.nodes[node]['utility']<0:\n",
        "\n",
        "def seperable_efficient_network(b,C):\n",
        "    n=len(C)\n",
        "    G=nx.empty_graph(n)\n",
        "    m=1  \n",
        "    RHS=C[0]-2*b[1]\n",
        "    print('RHS',RHS)\n",
        "    LHS=2*(m-1)*b[2]-C[m]  # for i in range(n), nodes start from 1 to n, m is the largest integer\n",
        "       # between 1 and n, m={2,n}, but in function nodes start from 0 to n-1, let t=m-1, m=t+1,  so \n",
        "        # LHS=2(m-2)-C[m-1] turn to LHS=2(t-1)-C[t]\n",
        "    print('LHS',LHS)\n",
        "    while ((LHS >= RHS) and (m < n)):\n",
        "        #print('This is m:',m)\n",
        "        #print('LHS',LHS)\n",
        "        m+=1\n",
        "        if m==n:\n",
        "            break\n",
        "        LHS=2*(m-1)*b[2]-C[m]\n",
        "        \n",
        "    if m > n:\n",
        "        print('No Efficient Network Exists!')\n",
        "    \n",
        "    m=m-1\n",
        "    \n",
        "    \n",
        "    connected_nodes=[]\n",
        "    for i in range(1, m + 1):\n",
        "        G.add_edge(0, i)\n",
        "        for j in range(i+1, m + 1):\n",
        "            if (b[1] - b[2]) >= 0.5 * (C[i] + C[j]):\n",
        "                G.add_edge(i, j)\n",
        "                connected_nodes.append([i,j])\n",
        "    \n",
        "    return G,m\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmGBX9DfvSR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"The following functions relaxes the conecpt of stability by allowing bilateral exchange\"\"\"\n",
        "def missed_opts_general_barg_bac(g,b,cx,neg_cost=0,depth=3):\n",
        "    node_utils= [node_utility_general(k,g,b,cx) for k in g.nodes()]\n",
        "    missing_links=[]\n",
        "    for e in list(nx.edges(nx.complement(g))):\n",
        "        g_tmp=g.copy()\n",
        "        g_tmp.add_edge(*e)\n",
        "        us_shift=node_utility_general(e[0],g_tmp,b,cx,depth)-node_utils[e[0]]\n",
        "        ud_shift=node_utility_general(e[1],g_tmp,b,cx,depth)-node_utils[e[1]]\n",
        "        if ((us_shift*ud_shift>=0) and (us_shift+ud_shift>0)):\n",
        "            missing_links.append(e)\n",
        "        elif ((us_shift*ud_shift<0) and (us_shift+ud_shift>neg_cost)):\n",
        "            missing_links.append(e)\n",
        "    return missing_links\n",
        "def missed_opts_general_barg(g,b,cx,neg_cost=0,depth=3):\n",
        "    node_utils= [node_utility_general(k,g,b,cx,depth=3) for k in g.nodes()]\n",
        "    missing_links=[]\n",
        "    for e in list(nx.edges(nx.complement(g))):\n",
        "        g_tmp=g.copy()\n",
        "        g_tmp.add_edge(*e)\n",
        "        us_shift=node_utility_general(e[0],g_tmp,b,cx,depth=3)-node_utils[e[0]]\n",
        "        ud_shift=node_utility_general(e[1],g_tmp,b,cx,depth=3)-node_utils[e[1]]\n",
        "        if (us_shift+ud_shift>0):\n",
        "            missing_links.append(e)\n",
        "        elif ((us_shift*ud_shift<0) and (us_shift+ud_shift>neg_cost)):\n",
        "            missing_links.append(e)\n",
        "    return missing_links\n",
        "def frust_list_general_barg(g,b,cx,neg_cost=0,depth=3):\n",
        "    node_utils= [node_utility_general(k,g,b,cx,depth=3) for k in g.nodes()]\n",
        "    frust_list=[]\n",
        "    for e in list(nx.edges(g)):\n",
        "        g_tmp=g.copy() \n",
        "        us_shift=node_utility_general(e[0],g_tmp,b,cx)-node_utils[e[0]]\n",
        "        ud_shift=node_utility_general(e[1],g_tmp,b,cx)-node_utils[e[1]]\n",
        "        if ((us_shift+ud_shift) > -neg_cost):\n",
        "            frust_list.append(e)\n",
        "    return frust_list\n",
        "def find_no_frustration_network_general_barg(g,b,cx,neg_cost=0,depth=3,M=1000):\n",
        "    f_list=frust_list_general_barg(g,b,cx,neg_cost=0,depth=depth)\n",
        "    g_tmp=g.copy()\n",
        "    while ((f_list) and (M>0)):\n",
        "        e_rem=rnd.choice(f_list)\n",
        "        g_tmp.remove_edge(e_rem[0],e_rem[1])\n",
        "        f_list=total_frust_list_general(g_tmp,b,cx,depth)\n",
        "        M=M-1\n",
        "    return g_tmp,M\n",
        "def find_no_envy_network_general_barg(g,b,cx,neg_cost=0,depth=3,M=1000):\n",
        "    en_list=missed_opts_general_barg(g,b,cx,neg_cost=neg_cost,depth=depth)\n",
        "    g_tmp=g.copy()\n",
        "    while ((en_list) and (M>0)):\n",
        "        e_add=rnd.choice(en_list)\n",
        "        g_tmp.add_edge(*e_add)\n",
        "        en_list=missed_opts_general_barg(g_tmp,b,cx,neg_cost=0,depth=depth)\n",
        "        #print(len(en_list))\n",
        "        M=M-1\n",
        "    return g_tmp,M\n",
        "def find_stable_network_general_barg(g,b,cx,depth=3,N=500,M1=1,M2=1,neg_cost_f=0,neg_cost_e=0):\n",
        "    Steps=N\n",
        "    set_network_util_attributes(g,b,cx,depth=depth)\n",
        "    g_sequence=[]\n",
        "    gt=g.copy()\n",
        "    L1=frust_list_general_barg(gt,b,cx,neg_cost=neg_cost_f,depth=depth)\n",
        "    L2=missed_opts_general_barg(gt,b,cx,neg_cost=neg_cost_e,depth=depth)\n",
        "    while ((len(L1)>0 or (len(L2)>0)) and (N>0)):\n",
        "        g_no_frust,Mf=find_no_frustration_network_general_barg(gt,b,cx,neg_cost=neg_cost_f,depth=depth,M=M1)\n",
        "        g_no_envy,Me=find_no_envy_network_general_barg(g_no_frust,b,cx,neg_cost=neg_cost_e,depth=depth,M=M2)\n",
        "        gt=g_no_envy\n",
        "        L1=frust_list_general_barg(gt,b,cx,neg_cost=neg_cost_f,depth=depth)\n",
        "        L2=missed_opts_general_barg(gt,b,cx,neg_cost=neg_cost_e,depth=depth)\n",
        "        N=N-1\n",
        "        set_network_util_attributes(gt,b,cx,depth=depth)\n",
        "        g_sequence.append(gt)\n",
        "        #print(N)\n",
        "        #print(len(L1),len(L2))\n",
        "    return gt,Steps-N,g_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oyFyX8t0vSSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"efficient networks\"\"\"\n",
        "\n",
        "def efficient_network(benefit,Cost):\n",
        "    G1,m=seperable_efficient_network(benefit,Cost)\n",
        "    CMS=seperable_cost(Cost)\n",
        "    L=all_utils_general(G1,b,CMS)\n",
        "    effi_network=sum(L)\n",
        "    \n",
        "    return effi_network, G1,m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUjFhkXrvSSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"find stable network and characteristic\"\"\"\n",
        "def stable_network_characteristic(b,Cve):    \n",
        "    G_in=nx.erdos_renyi_graph(len(Cve),0.1)\n",
        "    CMS=seperable_cost(Cve)\n",
        "    '''find stable network'''\n",
        "    \n",
        "    G,NN,G_T=find_stable_network_general_barg(G_in,b,CMS,depth=4,N=1000,M1=10,M2=1)\n",
        "    Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
        "    '''this is the stable network for each iteration'''\n",
        "    giant = G.subgraph(Gcc[0])\n",
        "    \n",
        "    '''get the nodes utility list of stable network '''\n",
        "    node_stable_util_list=all_utils_general(giant, b, CMS, depth=3)\n",
        "    \n",
        "    '''efficiency loss''' \n",
        "    \n",
        "    stable_total_utility=total_utility(giant)\n",
        "    eff_utility, G_1,m=efficient_network(b,Cve)\n",
        "    efficiency_loss=eff_utility-stable_total_utility\n",
        "    \n",
        "    \n",
        "    \n",
        "    return  giant, node_stable_util_list,eff_utility, G_1,efficiency_loss,m\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9qK38f-vSSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def figure_stable(b,Cve):   \n",
        "    \n",
        "    '''get parameter list, stable network and node utility list from input benefit and cost matrix'''\n",
        "    giant_stable, node_stable_util_l,eff_utility, G_efficient,efficiency_loss,m=stable_network_characteristic(b,Cve)\n",
        "\n",
        "    '''draw the stable network labeled with color'''\n",
        "    color_map=[]\n",
        "    for node in giant_stable:\n",
        "        if G_efficient.degree(node)<(len(Cve)-2):\n",
        "            color_map.append('cadetblue')\n",
        "        else: color_map.append('goldenrod')\n",
        "\n",
        "    fig_stable=plt.figure(figsize=(8,8),dpi=50)\n",
        "    nx.draw(giant_stable,pos=nx.spring_layout(giant_stable),node_size=1400, width=3, font_size=20,node_color=color_map, with_labels=True)\n",
        "    plt.title('Stable network',fontsize=25)\n",
        "\n",
        "    fig_pagerank=plt.figure(figsize=(8,8),dpi=50)\n",
        "    pagerank=sorted(nx.pagerank(giant_stable).items(),reverse = True)\n",
        "    first_degree_connected_nodes = list(giant_stable.neighbors(4))#7,4\n",
        "    second_degree_connected_nodes = []\n",
        "    for x in first_degree_connected_nodes:\n",
        "        second_degree_connected_nodes+=list(giant_stable.neighbors(x))\n",
        "    second_degree_connected_nodes.remove(4) #7,4\n",
        "    second_degree_connected_nodes = list(set(second_degree_connected_nodes))\n",
        "    subgraph_7 = nx.subgraph(giant_stable,first_degree_connected_nodes+second_degree_connected_nodes)\n",
        "\n",
        "    node_color = ['yellow' if v ==4 else 'lightcoral' for v in subgraph_7] #v==7,4\n",
        "    node_size =  [1700 if v == 4 else 1200 for v in subgraph_7]#v==7,4\n",
        "\n",
        "    nx.draw(subgraph_7, pos=nx.spring_layout(subgraph_7), node_color=node_color,node_size=node_size, font_size=20,with_labels=True)\n",
        "\n",
        "    plt.title('Page Rank',fontsize=25)\n",
        "    fig_efficient=plt.figure(figsize=(8,8),dpi=50)\n",
        "\n",
        "    nx.draw(G_efficient,pos=nx.spring_layout(G_efficient),node_size=1400,width=5, font_size=20,with_labels=True)\n",
        "    plt.title('Efficient Network',fontsize=25)\n",
        "    plt.show()\n",
        "    return fig_stable, fig_pagerank, fig_efficient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JEpytr9vSSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def paramiter_function(b,Cve):\n",
        "    \n",
        "    giant, node_stable_util_l,eff_utility, G_efficient,efficiency_loss,m=stable_network_characteristic(b,Cve)\n",
        "    # number_of_isolated_nodes_stable_network=len(Cvec)-len(giant.nodes())\n",
        "    \n",
        " \n",
        "    node_number=nx.number_of_nodes(giant)\n",
        "    pathlengths = []\n",
        "    pathlength_array=np.empty([node_number,node_number])\n",
        "    for v in giant.nodes():\n",
        "        spl = dict(nx.single_source_shortest_path_length(giant, v))        \n",
        "        for p in spl:\n",
        "            pathlengths.append(spl[p])\n",
        "            pathlength_array[v][p]=spl[p]  #shortest path length matrix\n",
        "    average_shortest_path_length=sum(pathlengths) / len(pathlengths)\n",
        "    \n",
        "    # histogram of path lengths\n",
        "    dist = {}\n",
        "    for p in pathlengths:\n",
        "        if p in dist:\n",
        "            dist[p] += 1\n",
        "        else:\n",
        "            dist[p] = 1\n",
        "    number_of_path_df = pd.DataFrame.from_dict(dist, orient='index')\n",
        "    degree_of_nodes=list(giant.degree)\n",
        "\n",
        "    print(\"---------Number of Stable Network:\",len(G_T))\n",
        "    return  all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "97mVGwcMvSSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 9 nodes network benefit and cost\n",
        "#Cve=[0.3,0.4,1,1.2,1.3,1.5,1.6,1.8,1.9] #0<c<2, c<b1-b2\n",
        "#b=[0,3.5,1.5,0.5,0.3]\n",
        "#Cve=[1.6,1.8,1.9,2.1,2.2,2.3,2.5,2.6,2.8] #1.5<ci<3, 1=b1-b2<ci<b1=4\n",
        "#b=[0,4,3,2,1]\n",
        "#Cve=[0.5,0.7,1,1.2,1.6,2.0,2.6,2.8,2.9] #0<c<2, cj<b1-b2(=1.5)<ci<b1=4\n",
        "#b=[0,4,2.5,1.5,0.5]\n",
        "\n",
        "### 8 nodes network benefit and cost\n",
        "#Cve=[0.3,0.4,1.2,1.3,1.5,1.6,1.8,1.9] #0<c<2, c<b1-b2\n",
        "#b=[0,3.5,1.5,1,0.5]\n",
        "#Cve=[1.8,1.9,2.1,2.2,2.3,2.5,2.6,2.9] #1.5<ci<3, 1=b1-b2<ci<b1=4\n",
        "#b=[0,4,3,2,1]\n",
        "#Cve=[0.5,0.7,1,1.2,1.6,2.0,2.6,2.8] #0<c<2, cj<b1-b2(=1.5)<ci<b1=4\n",
        "#b=[0,4,2.5,1.5,0.5]\n",
        "\n",
        "### 7 nodes network benefit and cost\n",
        "#Cve=[0.4,1.2,1.3,1.5,1.6,1.8,1.9] #0<c<2, c<b1-b2\n",
        "#b=[0,3.5,1.5,1,0.5]\n",
        "#Cve=[1.8,1.9,2.1,2.2,2.3,2.5,2.6] #1.5<ci<3, 1=b1-b2<ci<b1=4\n",
        "#b=[0,4,3,2,1]\n",
        "#Cve=[0.7,1,1.2,1.6,2.0,2.6,2.8] #0<c<2, cj<b1-b2(=1.5)<ci<b1=4\n",
        "#b=[0,4,2.5,1.5,0.5]\n",
        "\n",
        "### 6 nodes network benefit and cost\n",
        "#Cve=[0.4,1.2,1.5,1.6,1.8,1.9] #0<c<2, c<b1-b2\n",
        "#b=[0,3.5,1.5,1,0.5]\n",
        "#Cve=[1.8,1.9,2.1,2.2,2.3,2.5] #1.5<ci<3, 1=b1-b2<ci<b1=4\n",
        "#b=[0,4,3,2,1]\n",
        "#Cve=[0.5,0.7,1,2.0,2.6,2.8] #0<c<2, cj<b1-b2(=1.5)<ci<b1=4\n",
        "#b=[0,4,2.5,1.5,0.5]\n",
        "\n",
        "### 5 nodes network benefit and cost\n",
        "#Cve=[1.3,1.5,1.6,1.8,1.9] #0<c<2, c<b1-b2\n",
        "#b=[0,3.5,1.5,1,0.5]\n",
        "#Cve=[2.1,2.2,2.3,2.5,2.6] #1.5<ci<3, 1=b1-b2<ci<b1=4\n",
        "#b=[0,4,3,2,1]\n",
        "#Cve=[0.5,0.7,1.5,2.6,2.8] #0<c<2, cj<b1-b2(=1.5)<ci<b1=4\n",
        "#b=[0,4,2.5,1.5,0.5]\n",
        "\n",
        "### 4 nodes network benefit and cost\n",
        "#Cve=[1.3,1.5,1.6,1.8] #0<c<2, c<b1-b2\n",
        "#b=[0,3.5,1.5,1,0.5]\n",
        "#Cve=[2.1,2.2,2.3,2.5] #1.5<ci<3, 1=b1-b2<ci<b1=4\n",
        "#b=[0,4,3,2,1]\n",
        "#Cve=[0.7,1.5,2.6,2.8] #0<c<2, cj<b1-b2(=1.5)<ci<b1=4\n",
        "#b=[0,4,2.5,1.5,0.5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4JfGiFvvSSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"10 nodes network benefit and cost\"\"\"\n",
        "\"\"\"characteristics of stable networks\"\"\" \n",
        "# create a pdf file to store figures\n",
        "\n",
        "#Cve=[0.2,0.3,0.4,1,1.2,1.3,1.5,1.6,1.8,1.9] #0<c<2, c<b1-b2\n",
        "#b=[0,3.5,1.5,0.5,0.3]\n",
        "#Cve=[1.6,1.8,1.9,2.1,2.2,2.3,2.5,2.6,2.8,2.9] #1.5<ci<3, 1=b1-b2<ci<b1=4\n",
        "#b=[0,4,3,2,1]\n",
        "#Cve=[0.2,0.5,0.7,1,1.2,1.6,2.0,2.6,2.8,2.9] #0<c<2, cj<b1-b2(=1.5)<ci<b1=4\n",
        "#b=[0,4,2.5,1.5,0.3]\n",
        "#Cve=[1,2,3,4,5,6,7,8,9,10] #0<c<11, cj<b1-b2(=5)<ci<b1=12,n10_3_i_2\n",
        "#b=[0,12,7,4,3]\n",
        "#Cve=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0] #0<c<1.1, cj<b1-b2(=0.6)<ci<b1=1.5 n10_3_i_3\n",
        "#b=[0,1.5,0.9,0.5,0.3]\n",
        "#Cve=[5,7,8,10,12,13,15,16,18,20] #5<c<21, cj<b1-b2(=10)<ci<b1=30  n10_3_i_4\n",
        "#b=[0,30,20,15,3]\n",
        "Cve=[0.2,0.5,0.7,1,1.2,1.6,2.0,2.1,2.2,2.4] #0<c<2.5, cj<b1-b2(=1.3)<ci<b1=4 n10_3_i_5\n",
        "b=[0,4,2.7,1.5,0.3] \n",
        "\n",
        "#pp=PdfPages('/content/drive/My Drive/output_values/graph_n10_3_i_3.pdf')\n",
        "total_utility_stable=[] # initial stable network's total utilities list\n",
        "node_utility_stable=[] # initial a list to store the node utility list of each stable network \n",
        "stable_matrix=[b,Cve] # initial adjacency matrix of each stable network\n",
        "Efficiency_loss_list=[]\n",
        "closeness_centrality=[]\n",
        "betweenness_centrality=[]\n",
        "eigenvector_centrality=[]\n",
        "page_rank=[]\n",
        "triangles=[]\n",
        "clustering=[]\n",
        "\n",
        "eccentricity=[]\n",
        "diameter_radius_center_periphery_density=[]\n",
        "transitivity=[]\n",
        "effective_size=[]\n",
        "closeness_vitality=[]\n",
        "wiener_index=[]\n",
        "\n",
        "for i in range(3500):\n",
        "    \n",
        "    giant, node_stable_util_l,eff_utility, G_efficient,efficiency_loss,m=stable_network_characteristic(b,Cve)\n",
        "    \n",
        "    '''get the stable network adjacency matrix'''\n",
        "    arraystable=nx.convert_matrix.to_numpy_array(giant)\n",
        "    array=arraystable.tolist()\n",
        "    \n",
        "    if array in stable_matrix:\n",
        "        break \n",
        "    \n",
        "    stable_matrix.append(array)\n",
        "    print(\"Iteration :\", i)\n",
        "    print('---Efficient Network(may not stable) Utility:',\"{:.4f}\".format(eff_utility))\n",
        "    print('---Stable Network Utility:',\"{:.4f}\".format(total_utility(giant)))\n",
        "    print('---Efficiency Loss of Stable Network:',\"{:.4f}\".format(efficiency_loss))\n",
        "    '''get the efficiency loss list'''\n",
        "    Efficiency_loss_list.append(round(efficiency_loss,4))\n",
        "\n",
        "    '''total utilities of all stable networks'''\n",
        "    total_utility_stable.append(total_utility(giant))\n",
        "\n",
        "    '''append node utility list for each iteration'''\n",
        "    node_utility_stable.append(node_stable_util_l)\n",
        "\n",
        "    closeness_centrality.append(list(nx.closeness_centrality(giant).values()))\n",
        "    betweenness_centrality.append(list(nx.betweenness_centrality(giant).values()))\n",
        "    eigenvector_centrality.append(list(nx.eigenvector_centrality(giant).values()))\n",
        "    page_rank.append(list(nx.pagerank(giant).values()))\n",
        "    triangles.append(list(nx.triangles(giant).values()))\n",
        "    clustering.append(list(nx.clustering(giant).values())) # clustering coefficient\n",
        "    eccentricity.append(list(nx.eccentricity(giant).values()))\n",
        "    effective_size.append(list(nx.effective_size(giant).values()))\n",
        "    closeness_vitality.append(list(nx.closeness_vitality(giant).values()))\n",
        "\n",
        "    wiener_index.append(nx.wiener_index(giant))\n",
        "    transitivity.append(nx.transitivity(giant))\n",
        "\n",
        "    diameter_radius_center_periphery_density.append([nx.diameter(giant),nx.radius(giant),nx.center(giant),nx.periphery(giant),nx.density(giant)])\n",
        "    numbers_isolated=nx.number_of_isolates(giant)\n",
        "    print('The Largest m:', m)\n",
        "    print('Numbers of Isolated Nodes:',numbers_isolated)\n",
        "    \"\"\"fig_stable_1,fig_pagerank_1,fig_efficient_1 =figure_stable(b,Cve) \n",
        "    pp.savefig(fig_stable_1)\n",
        "    pp.savefig(fig_pagerank_1) \n",
        "    pp.savefig(fig_efficient_1)\"\"\"\n",
        "\n",
        "    \"\"\"# print \"Degree sequence\", degree_sequence\n",
        "    degree_sequence = sorted([d for n, d in giant.degree()], reverse=True)  # degree sequence\n",
        "\n",
        "    degreeCount = collections.Counter(degree_sequence)\n",
        "    deg, cnt = zip(*degreeCount.items())\n",
        "\n",
        "    fig_his, ax1 = plt.subplots()\n",
        "    plt.bar(deg, cnt, width=0.80, color='b')\n",
        "\n",
        "    plt.title(\"Degree Histogram\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.xlabel(\"Degree\")\n",
        "    ax1.set_xticks([d + 0.4 for d in deg])\n",
        "    ax1.set_xticklabels(deg)\n",
        "    dmax = max(degree_sequence)\"\"\"\n",
        "    \"\"\"# draw graph in inset\n",
        "    plt.axes([0.4, 0.4, 0.5, 0.5])\n",
        "    G = giant.subgraph(sorted(nx.connected_components(giant), key=len, reverse=True)[0])\n",
        "\n",
        "    plt.axis('off')\n",
        "    nx.draw_networkx_nodes(giant, pos = nx.spring_layout(giant), node_size=20)\n",
        "    nx.draw_networkx_edges(giant, pos = nx.spring_layout(giant), alpha=0.4)\n",
        "\n",
        "    #fig_plot=plt.figure(figsize=(8,8),dpi=50)\n",
        "    #plt.plot(degree_sequence, 'b-', marker='o')\n",
        "    #plt.title(\"Degree rank plot\")\n",
        "    #plt.ylabel(\"degree\")\n",
        "    #plt.xlabel(\"rank\")\n",
        "\n",
        "    # draw graph in inset\n",
        "    #plt.axes([0.45, 0.45, 0.45, 0.45])\n",
        "\n",
        "    #pos = nx.spring_layout(G)\n",
        "    #plt.axis('off')\n",
        "    #nx.draw_networkx_nodes(G, pos, node_size=20)\n",
        "    #nx.draw_networkx_edges(G, pos, alpha=0.4)\n",
        "\n",
        "    #plt.show()\n",
        "\n",
        "    #pp.savefig(fig_his)\n",
        "    #pp.savefig(fig_plot)\"\"\"\n",
        "#pp.close()\n",
        "\n",
        "# convert list to dataframe\n",
        "node_utility_df=pd.DataFrame(node_utility_stable)\n",
        "stable_matrix=pd.DataFrame(stable_matrix)\n",
        "Efficiency_loss=pd.DataFrame(Efficiency_loss_list)\n",
        "diameter_radius_center_periphery_density=pd.DataFrame(diameter_radius_center_periphery_density)\n",
        "\n",
        "wiener_index_df=pd.DataFrame(wiener_index)\n",
        "transitivity_df=pd.DataFrame(transitivity)\n",
        "\n",
        "closeness_df=pd.DataFrame(closeness_centrality)\n",
        "betweenness_df=pd.DataFrame(betweenness_centrality)\n",
        "eigenvector_df=pd.DataFrame(eigenvector_centrality)\n",
        "page_rank_df=pd.DataFrame(page_rank)\n",
        "triangles_df=pd.DataFrame(triangles)\n",
        "clustering_df=pd.DataFrame(clustering)\n",
        "eccentricity_df=pd.DataFrame(eccentricity)\n",
        "effective_size_df=pd.DataFrame(effective_size)\n",
        "closeness_vitality_df=pd.DataFrame(closeness_vitality)\n",
        "\n",
        "# the largest utility of the stable and efficient networks\n",
        "efficient_index=[index for index, value in enumerate(total_utility_stable) if value==max(total_utility_stable)]\n",
        "\n",
        "print('Efficient network index: ', efficient_index)   \n",
        "\n",
        "print('Efficiency loss network list', Efficiency_loss_list)\n",
        "\n",
        "#write dataframe to excel\n",
        "with pd.ExcelWriter('/content/drive/My Drive/output_values/output_n10_3_i_5.xlsx') as writer:\n",
        "        #node_utility_df.to_excel(writer,sheet_name=\"node utility\")\n",
        "        #stable_matrix.to_excel(writer,sheet_name=\"matrix\")\n",
        "        closeness_df.to_excel(writer,sheet_name=\"closeness_centrality\")\n",
        "        betweenness_df.to_excel(writer,sheet_name=\"betweenness_centrality\")\n",
        "        eigenvector_df.to_excel(writer,sheet_name=\"eigenvector_centrality\")\n",
        "        page_rank_df.to_excel(writer,sheet_name=\"page_rank\")\n",
        "        triangles_df.to_excel(writer,sheet_name=\"triangles\")\n",
        "        clustering_df.to_excel(writer,sheet_name=\"clustering\")\n",
        "        wiener_index_df.to_excel(writer,sheet_name=\"wiener_index\")\n",
        "        transitivity_df.to_excel(writer,sheet_name=\"transitivity\")\n",
        "        eccentricity_df.to_excel(writer,sheet_name=\"eccentricity\")\n",
        "        \n",
        "        diameter_radius_center_periphery_density.to_excel(writer,sheet_name=\"d_r_c_p_d\")\n",
        "        Efficiency_loss.to_excel(writer,sheet_name=\"Efficiency_loss\")\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6c1YgAUcvSSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_8N1qJ7vSSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNMMiD8evSSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P337fybvSST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}